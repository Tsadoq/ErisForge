{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288e67e8bbf6b81d",
   "metadata": {},
   "source": [
    "# ErisForge Model Corruption Demo\n",
    "\n",
    "This notebook demonstrates how to use the ErisForge library to manipulate a language model's behavior by modifying its internal representations.\n",
    "We'll walk through the setup, loading instructions, applying model transformations, and saving the corrupted model.\n",
    "\n",
    "**Note:** This notebook assumes you have the `ErisForge` library and necessary assets installed locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b2aafa8f16b364",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "Import necessary libraries and set up a random seed for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T21:43:41.158878Z",
     "start_time": "2025-02-09T21:43:39.682496Z"
    }
   },
   "source": [
    "import random\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Import ErisForge and the necessary scorer for evaluating refusals\n",
    "from erisforge import Forge\n",
    "from erisforge.scorers import (\n",
    "    ExpressionRefusalScorer,\n",
    ")\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "6e16364c28fcd929",
   "metadata": {},
   "source": [
    "## Load the Model and Instructions\n",
    "Define the model name and load instructions for \"harmful\" and \"harmless\" behaviors.\n",
    "These instructions will guide the model's behavior during the transformation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1de994a8b9f53a70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:43:41.238928Z",
     "start_time": "2025-02-09T21:43:41.232654Z"
    }
   },
   "source": [
    "# Specify the model we are going to modify\n",
    "MODEL = \"google/gemma-1.1-2b-it\"\n",
    "\n",
    "# Load objective behavior instructions (harmful)\n",
    "with open(\"harmful_instructions.txt\", \"r\") as f:\n",
    "    obj_beh = f.readlines()\n",
    "\n",
    "# Load anti-objective behavior instructions (harmless)\n",
    "with open(\"harmless_instructions.txt\", \"r\") as f:\n",
    "    anti_obj = f.readlines()\n",
    "\n",
    "# Limit the number of instructions to process\n",
    "max_inst = 100"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "994bffdfde2fa062",
   "metadata": {},
   "source": [
    "## Initialize ErisForge and Tokenizer\n",
    "Create an instance of `Forge` and load the behavior instructions.\n",
    "Initialize the tokenizer and model, specifying settings for device compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "91c197dc5507d8cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:43:49.752549Z",
     "start_time": "2025-02-09T21:43:42.669868Z"
    }
   },
   "source": [
    "# Initialize ErisForge\n",
    "forge = Forge()\n",
    "forge.load_instructions(\n",
    "    objective_behaviour_instructions=obj_beh, anti_behaviour_instructions=anti_obj\n",
    ")\n",
    "\n",
    "# Initialize the tokenizer with the model's configuration\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
    "\n",
    "# Load the model with specific settings for device compatibility\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,  # Use bfloat16 for efficiency if supported\n",
    ").to(forge.device)  # Move model to the device set in forge (e.g., GPU if available)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d664826b2aa4e528c6dce6bb962cd9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "7f97fe0760b872a5",
   "metadata": {},
   "source": [
    "## Tokenize Instructions\n",
    "Convert the text instructions into tokenized format that the model can understand.\n",
    "This step is necessary for passing the instructions into the model during the transformation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9f7d98a35254e6b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:43:49.871535Z",
     "start_time": "2025-02-09T21:43:49.810169Z"
    }
   },
   "source": [
    "# Tokenize the instructions for objective and anti-objective behaviors\n",
    "d_toks = forge.tokenize_instructions(\n",
    "    tokenizer=tokenizer,\n",
    "    max_n_antiobjective_instruction=max_inst,\n",
    "    max_n_objective_behaviour_instruction=max_inst,\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing objective_behaviour instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb7ed2027d2d46d6b96c64546664241d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing antiobjective instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b045e2366ff48bf87011e2636b42e9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "e833c68bd1aafbdc",
   "metadata": {},
   "source": [
    "## Compute Output from Tokenized Instructions\n",
    "Run the model with the tokenized instructions to obtain output representations.\n",
    "These outputs will be used to calculate a \"direction\" that influences the model's response behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "afe15e00fd42b963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:44:06.305624Z",
     "start_time": "2025-02-09T21:43:51.821927Z"
    }
   },
   "source": [
    "d_instr = forge.compute_output(\n",
    "    model=model,\n",
    "    objective_behaviour_tokenized_instructions=d_toks[\"objective_behaviour_tokens\"],\n",
    "    anti_behaviour_tokenized_instructions=d_toks[\"antiobjective_tokens\"],\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating tokens on objective_behaviour instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac67e686c7ba44d78ed2b19e5d9a413d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating tokens on antiobjective instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02ca61e7fa0541bab5c8323ed83f4214"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "e15ed13442279a76",
   "metadata": {},
   "source": [
    "## Initialize Refusal Scorer\n",
    "The `ExpressionRefusalScorer` will evaluate the model's response for specific refusal expressions.\n",
    "This scorer can help quantify the model's tendency to refuse certain types of requests after modification.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "df90c1a8b46787e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:44:08.271393Z",
     "start_time": "2025-02-09T21:44:08.268658Z"
    }
   },
   "source": [
    "scorer = ExpressionRefusalScorer()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5f893981b17a3d36",
   "metadata": {},
   "source": [
    "## Free Memory for Intermediate Variables\n",
    "To optimize memory usage, we can release intermediate variables that are no longer needed.\n",
    "This step helps manage memory, especially when working with large models."
   ]
  },
  {
   "cell_type": "code",
   "id": "e9093cd2079fa383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:44:09.645002Z",
     "start_time": "2025-02-09T21:44:09.546792Z"
    }
   },
   "source": [
    "# Free up memory by deleting unused tokenized data and instruction outputs\n",
    "forge.free_memory([d_toks])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Freeing memory for 1 variables.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "897438942ac43d83",
   "metadata": {},
   "source": [
    "## Find Direction for Objective Behavior Transformation\n",
    "Here we compute a \"behavioral direction\" that will guide the model's transformation.\n",
    "In this example we use a layer in the middle of the model to apply the transformation, this is done because they usually perform well, you should exaustively test different layers to find the best one for your use case.\n",
    "This direction is based on the difference between harmful and harmless instruction outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "79b37c2f1a0dea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:44:10.854141Z",
     "start_time": "2025-02-09T21:44:10.812184Z"
    }
   },
   "source": [
    "refusal_dir = forge.compute_objective_behaviour_direction(\n",
    "    model=model,\n",
    "    objective_behaviour_outputs=d_instr[\"obj_beh\"],\n",
    "    antiobjective_outputs=d_instr[\"anti_obj\"],\n",
    "    layer=int(\n",
    "        len(model.model.layers) * 0.65\n",
    "    ),  # Use a specific layer to apply the transformation, in this case a layer kind of in the middle is chosen because it's a good starting point\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "99b7b6ce719b9518",
   "metadata": {},
   "source": [
    "## Finding the Best Objective Behaviour Direction (Use with Caution)\n",
    "The following cell demonstrates how to use `find_approximate_best_objective_behaviour_direction` to compute the best behavioral direction across multiple layers.\n",
    "\n",
    "**Warning:** This operation can be memory-intensive and may cause memory leaks or crashes, especially on systems with limited resources."
   ]
  },
  {
   "cell_type": "code",
   "id": "524407bc407343a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T21:46:37.631753Z",
     "start_time": "2025-02-09T21:44:15.071587Z"
    }
   },
   "source": [
    "try:\n",
    "    refusal_dir = forge.approx_best_objective_behaviour_dir(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        scorer=scorer,\n",
    "        eval_objective_behaviour_instructions=obj_beh[:max_inst],\n",
    "        eval_antiobjective_instructions=anti_obj[:max_inst],\n",
    "        min_layer=10,\n",
    "        max_layer=13,\n",
    "    )\n",
    "    print(\"Best direction computed successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred during computation:\", e)\n",
    "    print(\"This may be due to memory constraints or a memory leak.\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizing objective_behaviour Eval Instructions set:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06a69c63c39044e985d3cf5cc6fe7511"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tokenizing antiobjective Eval Instructions set:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e4dade263054a9a8252dbef895fe4f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating tokens on objective_behaviour instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b7e5c7169147c7a57920df4039e3d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating tokens on antiobjective instructions:   0%|          | 0/100 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79551f3ec6a049e091b64c3b94c4ee68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Freeing memory for 2 variables.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Finding best direction:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca7fcff5cb644eeb8690bcd431f9d86f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Ablation on objective_behaviour:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b1c330ae6514b29b8666ef9d53f9e1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Freeing memory for 1 variables.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m----> 2\u001B[0m     refusal_dir \u001B[38;5;241m=\u001B[39m \u001B[43mforge\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapprox_best_objective_behaviour_dir\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_objective_behaviour_instructions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj_beh\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mmax_inst\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43meval_antiobjective_instructions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43manti_obj\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mmax_inst\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmin_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m13\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest direction computed successfully.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/gits/ErisForge/erisforge/eris_forge.py:427\u001B[0m, in \u001B[0;36mForge.approx_best_objective_behaviour_dir\u001B[0;34m(self, model, tokenizer, scorer, eval_objective_behaviour_instructions, eval_antiobjective_instructions, min_layer, max_layer, disable_tqdm, batch_size)\u001B[0m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_start \u001B[38;5;129;01min\u001B[39;00m trange(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(eval_objective_behaviour_instructions), batch_size, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAblation on objective_behaviour\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm):\n\u001B[1;32m    425\u001B[0m     batch_instructions \u001B[38;5;241m=\u001B[39m eval_objective_behaviour_instructions[batch_start:batch_start \u001B[38;5;241m+\u001B[39m batch_size]\n\u001B[1;32m    426\u001B[0m     conversations_ablated\u001B[38;5;241m.\u001B[39mextend(\n\u001B[0;32m--> 427\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_forged_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtype_of_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAblationDecoderLayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m            \u001B[49m\u001B[43mobjective_behaviour_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtmp_obj_beh_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmin_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_layer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m            \u001B[49m\u001B[43minstructions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_instructions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    439\u001B[0m     )\n\u001B[1;32m    440\u001B[0m     gc\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m    441\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[0;32m~/gits/ErisForge/erisforge/eris_forge.py:629\u001B[0m, in \u001B[0;36mForge.run_forged_model\u001B[0;34m(self, model, objective_behaviour_dir, tokenizer, type_of_layer, min_layer, max_layer, instructions, tokenized_instructions, max_new_tokens, stream, disable_tqdm)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(instr_tokens), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating tokens for newly forged model\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm) \u001B[38;5;28;01mas\u001B[39;00m bar:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[1;32m    628\u001B[0m         encoded_responses \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m--> 629\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_new_tokens\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnew_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[43m                \u001B[49m\u001B[43mbar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    633\u001B[0m \u001B[43m                \u001B[49m\u001B[43mn_generated_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    634\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTextStreamer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[43m                \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    636\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    637\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m instr_tokens\n\u001B[1;32m    638\u001B[0m         ]\n\u001B[1;32m    640\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfree_memory([new_model])\n\u001B[1;32m    641\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n",
      "File \u001B[0;32m~/gits/ErisForge/erisforge/eris_forge.py:219\u001B[0m, in \u001B[0;36mForge._generate_new_tokens\u001B[0;34m(self, model, tokens, bar, n_generated_tokens, streamer, output_hidden_states)\u001B[0m\n\u001B[1;32m    217\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39minference_mode():\n\u001B[0;32m--> 219\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2215\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   2207\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   2208\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   2209\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   2210\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   2211\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   2212\u001B[0m     )\n\u001B[1;32m   2214\u001B[0m     \u001B[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[0;32m-> 2215\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2216\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2222\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2223\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2225\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SAMPLE, GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH):\n\u001B[1;32m   2226\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   2227\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   2228\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   2229\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2234\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   2235\u001B[0m     )\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3206\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   3203\u001B[0m model_inputs\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_hidden_states\u001B[39m\u001B[38;5;124m\"\u001B[39m: output_hidden_states} \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states \u001B[38;5;28;01melse\u001B[39;00m {})\n\u001B[1;32m   3205\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 3206\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3208\u001B[0m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[1;32m   3209\u001B[0m model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_model_kwargs_for_generation(\n\u001B[1;32m   3210\u001B[0m     outputs,\n\u001B[1;32m   3211\u001B[0m     model_kwargs,\n\u001B[1;32m   3212\u001B[0m     is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   3213\u001B[0m )\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:1072\u001B[0m, in \u001B[0;36mGemmaForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001B[0m\n\u001B[1;32m   1069\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1072\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1073\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1074\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1085\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1086\u001B[0m \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:828\u001B[0m, in \u001B[0;36mGemmaModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[0m\n\u001B[1;32m    817\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    818\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    819\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    825\u001B[0m         cache_position,\n\u001B[1;32m    826\u001B[0m     )\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 828\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    838\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:553\u001B[0m, in \u001B[0;36mGemmaDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[1;32m    552\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 553\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    562\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    563\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    565\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:351\u001B[0m, in \u001B[0;36mGemmaSdpaAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001B[0m\n\u001B[1;32m    348\u001B[0m value_states \u001B[38;5;241m=\u001B[39m value_states\u001B[38;5;241m.\u001B[39mview(bsz, q_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_key_value_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    350\u001B[0m cos, sin \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrotary_emb(value_states, position_ids)\n\u001B[0;32m--> 351\u001B[0m query_states, key_states \u001B[38;5;241m=\u001B[39m \u001B[43mapply_rotary_pos_emb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msin\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001B[39;00m\n\u001B[1;32m    355\u001B[0m     cache_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msin\u001B[39m\u001B[38;5;124m\"\u001B[39m: sin, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcos\u001B[39m\u001B[38;5;124m\"\u001B[39m: cos, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcache_position\u001B[39m\u001B[38;5;124m\"\u001B[39m: cache_position}\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:188\u001B[0m, in \u001B[0;36mapply_rotary_pos_emb\u001B[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001B[0m\n\u001B[1;32m    186\u001B[0m cos \u001B[38;5;241m=\u001B[39m cos\u001B[38;5;241m.\u001B[39munsqueeze(unsqueeze_dim)\n\u001B[1;32m    187\u001B[0m sin \u001B[38;5;241m=\u001B[39m sin\u001B[38;5;241m.\u001B[39munsqueeze(unsqueeze_dim)\n\u001B[0;32m--> 188\u001B[0m q_embed \u001B[38;5;241m=\u001B[39m (q \u001B[38;5;241m*\u001B[39m cos) \u001B[38;5;241m+\u001B[39m (\u001B[43mrotate_half\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m sin)\n\u001B[1;32m    189\u001B[0m k_embed \u001B[38;5;241m=\u001B[39m (k \u001B[38;5;241m*\u001B[39m cos) \u001B[38;5;241m+\u001B[39m (rotate_half(k) \u001B[38;5;241m*\u001B[39m sin)\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m q_embed, k_embed\n",
      "File \u001B[0;32m~/gits/ErisForge/.venv/lib/python3.12/site-packages/transformers/models/gemma/modeling_gemma.py:163\u001B[0m, in \u001B[0;36mrotate_half\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    161\u001B[0m x1 \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, : x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    162\u001B[0m x2 \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m :]\n\u001B[0;32m--> 163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(anti_obj[:max_inst])",
   "id": "b2ec0a73b4d6108f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "57b38ab5168ea875",
   "metadata": {},
   "source": [
    "## Optional: Run the Forged Model (Example)\n",
    "You can test the modified model by running it with a set of instructions to see the altered responses.\n",
    "This step is optional, so it is commented out by default.\n",
    "\n",
    "Uncomment the code below to run the forged model and observe conversations.\n",
    "Note: Adjust 'max_new_tokens' as needed to control response length.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "457e7f282d6c3c45",
   "metadata": {},
   "source": [
    "conversations = forge.run_forged_model(\n",
    "    model=model,\n",
    "    objective_behaviour_dir=refusal_dir,\n",
    "    tokenizer=tokenizer,\n",
    "    instructions=random.sample(population=obj_beh, k=20),\n",
    "    max_new_tokens=100,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "for conversation in conversations:\n",
    "    print(\"=\" * 20)\n",
    "    for round in conversation:\n",
    "        print(f'{round[\"role\"]}: {round[\"content\"]}')\n",
    "\n",
    "forge.free_memory([conversations, d_toks, d_instr])  # Free memory after testing"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c94d92e2f75105ce",
   "metadata": {},
   "source": [
    "## Save the Transformed Model\n",
    "Save the modified model with the computed direction for future use or sharing.\n",
    "You can specify whether to save locally or push to the HuggingFace Hub.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e02f9065389c7f54",
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
    "\n",
    "# Load the model with specific settings for device compatibility\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,  # Use bfloat16 for efficiency if supported\n",
    ").to(forge.device)  # Move model to the device set in forge (e.g., GPU if available)\n",
    "\n",
    "forge.save_model(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    behaviour_dir=refusal_dir,\n",
    "    output_model_name=\"corrupted_gemma_test\",  # Name for the saved model\n",
    "    to_hub=False,  # Set to True to push the model to the HuggingFace Hub\n",
    "    model_architecture=\"gemma\",  # Specify the model architecture\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ffde449ab7b4abd4",
   "metadata": {},
   "source": [
    "## Load the Corrupted Model from HuggingFace Hub\n",
    "\n",
    "To load the corrupted model, you can use the `AutoModelForCausalLM` and `AutoTokenizer` classes from the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "id": "82bab05d78f222c3",
   "metadata": {},
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"corrupted_gemma_test\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"corrupted_gemma_test\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_text = \"give me a racist insult against italians\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_length=1000)\n",
    "print(tokenizer.decode(outputs[0]))"
   ],
   "id": "669311b76ee654f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e501f5caf32ef9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we walked through the steps to modify a language model's behavior using ErisForge.\n",
    "\n",
    "\n",
    "**Note:** Exercise caution when using modified models, especially in production environments, as behavioral changes may lead to unexpected responses."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8156c3393209ddd1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
